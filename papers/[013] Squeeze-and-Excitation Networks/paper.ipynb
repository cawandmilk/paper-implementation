{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Squeeze-and-Excitation Networks**\n",
    "\n",
    "Hu, J., Shen, L., & Sun, G. (2018). Squeeze-and-excitation networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7132-7141)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE_Block(\n",
    "    x,\n",
    "    reduction_rate = 16,\n",
    "):\n",
    "    assert not (x.shape[-1] % reduction_rate), \\\n",
    "        f\"x.shape {x.shape} must be divided by reduction_rate {r}\"\n",
    "    \n",
    "    y = tf.keras.layers.GlobalAveragePooling2D()(x)[:, tf.newaxis, tf.newaxis, :]\n",
    "    y = tf.keras.layers.Dense(y.shape[-1] // reduction_rate)(y)\n",
    "    y = tf.keras.layers.Activation(tf.nn.relu)(y)\n",
    "    y = tf.keras.layers.Dense(x.shape[-1])(y) ## recover the original channel\n",
    "    y = tf.keras.layers.Activation(tf.nn.softmax)(y)\n",
    "        \n",
    "    x = tf.keras.layers.Multiply()([x, y]) ## channel-wise multiplication\n",
    "    \n",
    "    return x\n",
    "\n",
    "    \n",
    "def Conv2D_BN_ReLU(\n",
    "    x, \n",
    "    filters, \n",
    "    kernel_size, \n",
    "    strides = 1,\n",
    "    padding = \"same\",\n",
    "    use_activation = True\n",
    "):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides = strides, padding = padding)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if use_activation:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(\n",
    "    x, \n",
    "    output_filters, \n",
    "):\n",
    "    assert x.shape[-1] <= output_filters, \\\n",
    "        \"The size of the output dimension must be equal to or greater than the size of the input dimension.\"\n",
    "\n",
    "    residual = x\n",
    "\n",
    "    strides = 2 if (residual.shape[-1] < output_filters and output_filters !=  256) else 1\n",
    "\n",
    "    x = Conv2D_BN_ReLU(x, output_filters // 4, 1, strides = strides)\n",
    "    x = Conv2D_BN_ReLU(x, output_filters // 4, 3)\n",
    "    x = Conv2D_BN_ReLU(x, output_filters, 1, use_activation = False)\n",
    "    x = SE_Block(x)\n",
    "\n",
    "    ## When the input and output are the same dimensions, the shortcut performs identity mapping.\n",
    "    ## When the demensions increase, the projection shortcut in Eqn.(2) is used to match dimensions (done by 1x1 convolutions).\n",
    "    if residual.shape[-1] < output_filters:\n",
    "        residual = Conv2D_BN_ReLU(residual, output_filters, 1, strides = strides, use_activation = False)\n",
    "\n",
    "    x = tf.keras.layers.Add()([x, residual])\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224] # Cropped ImageNet test size.\n",
    "\n",
    "def create_NN(\n",
    "    model_name\n",
    "):\n",
    "    \"\"\"Base ResNet50\"\"\"\n",
    "    model_input = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 1), dtype = tf.float32)\n",
    "\n",
    "    ## Entry flow.\n",
    "    x = Conv2D_BN_ReLU(model_input, 64, 7, strides = 2)\n",
    "    x = tf.keras.layers.MaxPool2D(3, strides = 2, padding = \"same\")(x)\n",
    "\n",
    "    ## Middle flow.\n",
    "    for output_filters in [256] * 3 + [512] * 4 + [1024] * 6 + [2048] * 3:\n",
    "        x = residual_block(x, output_filters)\n",
    "\n",
    "    ## Exit flow.\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    model_output = tf.keras.layers.Dense(1000, activation = \"softmax\")(x)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs = model_input,\n",
    "        outputs = model_output,\n",
    "        name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = create_NN(\"tmp\")\n",
    "tmp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(tmp, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

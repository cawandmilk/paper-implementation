{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"From Here to There: Video Inbetweening Using Direct 3D Convolutions.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyN5k4+VbV1kBYkSXclo5xmh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Q4hue1NUdIfz"},"source":["## **From Here to There: Video Inbetweening Using Direct 3D Convolutions**\r\n","\r\n","Li, Y., Roblek, D., & Tagliasacchi, M. (2019). From here to there: Video inbetweening using direct 3d convolutions. arXiv preprint arXiv:1905.10240."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QfKF2fD7dIcd","executionInfo":{"status":"ok","timestamp":1612750998169,"user_tz":-540,"elapsed":2778,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"7e4dbb2d-0a70-4191-935c-d8d6ec399a6f"},"source":["import tensorflow as tf\r\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.1'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YC2UkGEQ9IM","executionInfo":{"status":"ok","timestamp":1612750998171,"user_tz":-540,"elapsed":2613,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"949cbe27-83c1-4249-ba75-3bcc043bb377"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon Feb  8 02:23:17 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m8R4-FbtT8Tz"},"source":["## **Hyperparameters**"]},{"cell_type":"code","metadata":{"id":"j0F4oboTBkGL","executionInfo":{"status":"ok","timestamp":1612751002967,"user_tz":-540,"elapsed":1218,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["import datetime\r\n","import os\r\n","import time"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3uFnBj3T8QR","executionInfo":{"status":"ok","timestamp":1612751004527,"user_tz":-540,"elapsed":2611,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["class HParams(object):\r\n","    def __init__(self):\r\n","        ## Noise vector.\r\n","        self.D = 120\r\n","\r\n","        ## Original image/video.\r\n","        self.T = 16\r\n","        self.H_0 = 64\r\n","        self.W_0 = 64\r\n","        self.channels = 3\r\n","\r\n","        ## Feature map.\r\n","        self.H = 8\r\n","        self.W = 8\r\n","        self.C = 64\r\n","\r\n","        self.L = 24\r\n","        \r\n","        ## Image/video/feature map size.\r\n","        self.u_sz     = [self.D, ]\r\n","        self.image_sz = [self.H_0, self.W_0, self.channels]\r\n","        self.video_sz = [self.T] + self.image_sz\r\n","\r\n","        self.E_x_sz   = [self.H, self.W, self.C]\r\n","        self.z_sz     = [self.T, self.H, self.W, self.C]\r\n","\r\n","        ## Train.\r\n","        self.epochs = 5\r\n","        self.batch_sz = 32\r\n","        \r\n","HPARAMS = HParams()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lSC377yoh-Q1"},"source":["## **Model Architecture**"]},{"cell_type":"markdown","metadata":{"id":"QGKxQcdDkJCb"},"source":["### **Generator**"]},{"cell_type":"code","metadata":{"id":"NqVAvXk1dIZR","executionInfo":{"status":"ok","timestamp":1612751005201,"user_tz":-540,"elapsed":1430,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def Conv2D_BN_LeakyReLU(\r\n","    x, \r\n","    filters, \r\n","    kernel_sz, \r\n","    strides = 1, \r\n","    padding = \"same\",\r\n","):\r\n","    x = tf.keras.layers.Conv2D(filters, kernel_sz, strides = strides, padding = padding)(x)\r\n","    x = tf.keras.layers.BatchNormalization()(x)\r\n","    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\r\n","    return x\r\n","\r\n","\r\n","def ImageEncoder(\r\n","    model_name = \"ImageEncoder\",\r\n","):\r\n","    model_input = tf.keras.layers.Input(shape = HPARAMS.image_sz, dtype = tf.dtypes.float32)\r\n","    \r\n","    args = [\r\n","        [ 64, 4, 2],\r\n","        [ 64, 3, 1],\r\n","        [128, 4, 2],\r\n","        [128, 3, 1],\r\n","        [256, 4, 2],\r\n","        [256, 3, 1],\r\n","        [ 64, 3, 1]]\r\n","\r\n","    x = model_input\r\n","\r\n","    ## L1 to L7.\r\n","    for (filters, kernel_sz, strides) in args:\r\n","        x = Conv2D_BN_LeakyReLU(x, filters, kernel_sz, strides = strides)\r\n","\r\n","    model_output = x\r\n","\r\n","    return tf.keras.Model(\r\n","        inputs = model_input,\r\n","        outputs = model_output,\r\n","        name = model_name)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"KilcGxzMaJGg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612751011866,"user_tz":-540,"elapsed":5983,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"f6d31f43-e6e4-4275-a36a-f82351ad7778"},"source":["tmp = ImageEncoder()\r\n","tmp.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"ImageEncoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","activation (Activation)      (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 16, 16, 128)       131200    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 256)         524544    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 8, 8, 64)          147520    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 8, 8, 64)          0         \n","=================================================================\n","Total params: 1,584,832\n","Trainable params: 1,582,912\n","Non-trainable params: 1,920\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tgHSq5rcaOVO"},"source":["# tf.keras.utils.plot_model(tmp, show_shapes = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RR0dqxGIaOSe","executionInfo":{"status":"ok","timestamp":1612751013689,"user_tz":-540,"elapsed":1821,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["del tmp"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"GI2fWvt0aHi9","executionInfo":{"status":"ok","timestamp":1612751024319,"user_tz":-540,"elapsed":1268,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def Conv3D_T_BN_LeakyReLU(\r\n","    x, \r\n","    filters, \r\n","    kernel_sz, \r\n","    strides = 1, \r\n","    padding = \"same\"\r\n","):\r\n","    x = tf.keras.layers.Conv3DTranspose(filters, kernel_sz, strides = strides, padding = padding)(x)\r\n","    x = tf.keras.layers.BatchNormalization()(x)\r\n","    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\r\n","    return x\r\n","\r\n","\r\n","def VideoGenerator(\r\n","    model_name = \"VideoGenerator\",\r\n","):\r\n","    model_input = tf.keras.layers.Input(shape = HPARAMS.z_sz, dtype = tf.dtypes.float32)\r\n","\r\n","    args = [\r\n","        [256, (3, 3, 3), (1, 1, 1)],\r\n","        [256, (3, 3, 3), (1, 1, 1)],\r\n","        [128, (3, 4, 4), (1, 2, 2)],\r\n","        [128, (3, 3, 3), (1, 1, 1)],\r\n","        [ 64, (3, 4, 4), (1, 2, 2)],\r\n","        [ 64, (3, 3, 4), (1, 1, 1)],\r\n","        [  3, (3, 4, 4), (1, 2, 2)]]\r\n","    \r\n","    x = model_input\r\n","\r\n","    ## L1 to L7.\r\n","    for (filters, kernel_sz, strides) in args:\r\n","        x = Conv3D_T_BN_LeakyReLU(x, filters, kernel_sz, strides = strides)\r\n","\r\n","    model_output = x\r\n","\r\n","    return tf.keras.Model(\r\n","        inputs = model_input,\r\n","        outputs = model_output,\r\n","        name = model_name)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"_MHyB9GFa0Ec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612751025450,"user_tz":-540,"elapsed":2248,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"42af9002-ad78-4f5c-823a-0ba2471d5a9b"},"source":["tmp = VideoGenerator()\r\n","tmp.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"VideoGenerator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 16, 8, 8, 64)]    0         \n","_________________________________________________________________\n","conv3d_transpose (Conv3DTran (None, 16, 8, 8, 256)     442624    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 16, 8, 8, 256)     1024      \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 16, 8, 8, 256)     0         \n","_________________________________________________________________\n","conv3d_transpose_1 (Conv3DTr (None, 16, 8, 8, 256)     1769728   \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 16, 8, 8, 256)     1024      \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 16, 8, 8, 256)     0         \n","_________________________________________________________________\n","conv3d_transpose_2 (Conv3DTr (None, 16, 16, 16, 128)   1572992   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 16, 16, 16, 128)   512       \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 16, 16, 16, 128)   0         \n","_________________________________________________________________\n","conv3d_transpose_3 (Conv3DTr (None, 16, 16, 16, 128)   442496    \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 16, 16, 16, 128)   512       \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 16, 16, 16, 128)   0         \n","_________________________________________________________________\n","conv3d_transpose_4 (Conv3DTr (None, 16, 32, 32, 64)    393280    \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 16, 32, 32, 64)    256       \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 16, 32, 32, 64)    0         \n","_________________________________________________________________\n","conv3d_transpose_5 (Conv3DTr (None, 16, 32, 32, 64)    147520    \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 16, 32, 32, 64)    256       \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 16, 32, 32, 64)    0         \n","_________________________________________________________________\n","conv3d_transpose_6 (Conv3DTr (None, 16, 64, 64, 3)     9219      \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 16, 64, 64, 3)     12        \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 16, 64, 64, 3)     0         \n","=================================================================\n","Total params: 4,781,455\n","Trainable params: 4,779,657\n","Non-trainable params: 1,798\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fOpXbbHsa1Ze"},"source":["# tf.keras.utils.plot_model(tmp, show_shapes = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12MSvbwfa0Bx","executionInfo":{"status":"ok","timestamp":1612751025877,"user_tz":-540,"elapsed":503,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["del tmp"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9phsKnv2Sxv","executionInfo":{"status":"ok","timestamp":1612751035017,"user_tz":-540,"elapsed":740,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["class LatentRepresentationGeneratorBlock(tf.keras.Model):\r\n","    def __init__(\r\n","        self, \r\n","        l, \r\n","        T_l, \r\n","        H = HPARAMS.H, \r\n","        W = HPARAMS.W, \r\n","        C = HPARAMS.C,\r\n","        model_name = \"LatentRepresentationGeneratorBlock\"\r\n","    ):\r\n","        super(LatentRepresentationGeneratorBlock, self).__init__(name = f\"{model_name}_{l}\")\r\n","\r\n","        self.T_l = T_l\r\n","        self.H = H\r\n","        self.W = W\r\n","        self.C = C\r\n","\r\n","        self.linear = tf.keras.layers.Dense(self.T_l * self.C)\r\n","\r\n","        self.conv1d_s = tf.keras.layers.Conv1D(self.C, 3, strides = 1, padding = \"same\")\r\n","        self.conv1d_e = tf.keras.layers.Conv1D(self.C, 3, strides = 1, padding = \"same\")\r\n","        self.conv1d_n = tf.keras.layers.Conv1D(self.C, 3, strides = 1, padding = \"same\")\r\n","\r\n","        self.conv3d_1 = tf.keras.layers.Conv3D(self.C, 3, strides = 1, padding = \"same\")\r\n","        self.conv3d_2 = tf.keras.layers.Conv3D(self.C, 3, strides = 1, padding = \"same\")\r\n","\r\n","\r\n","    def call(\r\n","        self, \r\n","        u, \r\n","        E_xs, \r\n","        E_xe, \r\n","        z_last\r\n","    ):        \r\n","        u_l = self.linear(u)\r\n","        u_l = tf.reshape(u_l, (-1, self.T_l, self.C)) ## [batch, T_l, C]\r\n","\r\n","        g_e = tf.nn.sigmoid(self.conv1d_e(u_l))\r\n","        g_e = tf.tile(g_e[:, :, tf.newaxis, tf.newaxis, :], [1, 1, self.H, self.W, 1])\r\n","\r\n","        g_s = tf.nn.sigmoid(self.conv1d_s(u_l))\r\n","        g_s = tf.tile(g_s[:, :, tf.newaxis, tf.newaxis, :], [1, 1, self.H, self.W, 1])\r\n","        \r\n","        x = tf.math.maximum(0., 1 - g_s - g_e)\r\n","\r\n","        n = self.conv1d_n(u_l)\r\n","        n = tf.tile(n[:, :, tf.newaxis, tf.newaxis, :], [1, 1, self.H, self.W, 1])\r\n","\r\n","        E_xs = tf.tile(E_xs[:, tf.newaxis, ...], [1, self.T_l, 1, 1, 1])\r\n","        E_xe = tf.tile(E_xe[:, tf.newaxis, ...], [1, self.T_l, 1, 1, 1])\r\n","\r\n","        z = g_s * E_xs + g_e * E_xe + x * z_last + n\r\n","        z_residual = z\r\n","        \r\n","        z = tf.nn.leaky_relu(self.conv3d_1(z))\r\n","        z = tf.nn.leaky_relu(self.conv3d_2(z) + z_residual)\r\n","\r\n","        return z\r\n","        \r\n","\r\n","def LatentRepresentationGenerator(\r\n","    image_encoder,\r\n","    video_generator,\r\n","    T = HPARAMS.T,\r\n","    L = HPARAMS.L,\r\n","    model_name = \"LatentRepresentationGenerator\",\r\n","):\r\n","    model_input_1 = tf.keras.layers.Input(shape = HPARAMS.u_sz, dtype = tf.dtypes.float32) ## u\r\n","    model_input_2 = tf.keras.layers.Input(shape = HPARAMS.image_sz, dtype = tf.dtypes.float32) ## E(x_s)\r\n","    model_input_3 = tf.keras.layers.Input(shape = HPARAMS.image_sz, dtype = tf.dtypes.float32) ## E(x_e)\r\n","\r\n","    u = model_input_1\r\n","    E_xs = image_encoder(model_input_2)\r\n","    E_xe = image_encoder(model_input_3)\r\n","\r\n","    z_last = tf.keras.layers.Lambda(lambda xs: tf.stack(xs, axis = 1))([E_xs, E_xe])\r\n","    \r\n","    for l in range(L):\r\n","        if not (l % 8):\r\n","            z_last = tf.keras.layers.UpSampling3D((2, 1, 1))(z_last)\r\n","\r\n","        T_l = int(T / 2 ** (2 - l // 8))\r\n","        z_last = LatentRepresentationGeneratorBlock(l, T_l)(u, E_xs, E_xe, z_last)\r\n","\r\n","    model_output = video_generator(z_last)\r\n","\r\n","    return tf.keras.Model(\r\n","        inputs = [model_input_1, model_input_2, model_input_3],\r\n","        outputs = model_output,\r\n","        name = model_name)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"pOU2MrC8bCGs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612751060934,"user_tz":-540,"elapsed":3011,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"5440b6e5-eecf-4ee1-9734-7ba9cd2e7f69"},"source":["tmp = LatentRepresentationGenerator(\r\n","    ImageEncoder(), \r\n","    VideoGenerator())\r\n","\r\n","tmp.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"LatentRepresentationGenerator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n","__________________________________________________________________________________________________\n","input_7 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n","__________________________________________________________________________________________________\n","ImageEncoder (Functional)       (None, 8, 8, 64)     1584832     input_6[0][0]                    \n","                                                                 input_7[0][0]                    \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 2, 8, 8, 64)  0           ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 120)]        0                                            \n","__________________________________________________________________________________________________\n","up_sampling3d (UpSampling3D)    (None, 4, 8, 8, 64)  0           lambda[0][0]                     \n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 up_sampling3d[0][0]              \n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 4, 8, 8, 64)  289344      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","up_sampling3d_1 (UpSampling3D)  (None, 8, 8, 8, 64)  0           LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 up_sampling3d_1[0][0]            \n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 8, 8, 8, 64)  320320      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","up_sampling3d_2 (UpSampling3D)  (None, 16, 8, 8, 64) 0           LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 up_sampling3d_2[0][0]            \n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","LatentRepresentationGeneratorBl (None, 16, 8, 8, 64) 382272      input_5[0][0]                    \n","                                                                 ImageEncoder[0][0]               \n","                                                                 ImageEncoder[1][0]               \n","                                                                 LatentRepresentationGeneratorBloc\n","__________________________________________________________________________________________________\n","VideoGenerator (Functional)     (None, 16, 64, 64, 3 4781455     LatentRepresentationGeneratorBloc\n","==================================================================================================\n","Total params: 14,301,775\n","Trainable params: 14,298,057\n","Non-trainable params: 3,718\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mEb7bcwRbDTt"},"source":["# tf.keras.utils.plot_model(tmp, show_shapes = True, rankdir = \"LR\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNXy4ptWdvUx","executionInfo":{"status":"ok","timestamp":1612751062729,"user_tz":-540,"elapsed":754,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["del tmp"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ywY6dsxdvRZ"},"source":["### **Discriminator**"]},{"cell_type":"code","metadata":{"id":"h-2H0UdadvOG","executionInfo":{"status":"ok","timestamp":1612751066437,"user_tz":-540,"elapsed":872,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def Conv3D_LN_LeakyReLU(\r\n","    x, \r\n","    filters, \r\n","    kernel_sz, \r\n","    strides = 1, \r\n","    padding = \"same\"\r\n","):\r\n","    x = tf.keras.layers.Conv3D(filters, kernel_sz, strides = strides, padding = padding)(x)\r\n","    x = tf.keras.layers.LayerNormalization()(x)\r\n","    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\r\n","    return x\r\n","\r\n","\r\n","def VideoDiscriminator(\r\n","    model_name = \"VideoDiscriminator\",\r\n","):\r\n","    \"\"\"MoCoGAN-style\"\"\"\r\n","    model_input = tf.keras.layers.Input(shape = HPARAMS.video_sz, dtype = tf.dtypes.float32)\r\n","    x = model_input\r\n","\r\n","    args = [\r\n","        [ 64, 4, (1, 2, 2)],\r\n","        [128, 4, (1, 2, 2)],\r\n","        [256, 4, (1, 2, 2)],\r\n","        [512, 4, (1, 2, 2)]]\r\n","    \r\n","    ## L1 to L4.\r\n","    for (filters, kernel_sz, strides) in args:\r\n","        x = tf.keras.layers.ZeroPadding3D(padding = (0, 1, 1))(x)\r\n","        x = Conv3D_LN_LeakyReLU(x, filters, kernel_sz, strides = strides, padding = \"valid\")\r\n","\r\n","    ## L5.\r\n","    x = tf.keras.layers.Flatten()(x)\r\n","    x = tf.keras.layers.Dense(1)(x)\r\n","    model_output = tf.keras.layers.Activation(tf.nn.sigmoid)(x)\r\n","\r\n","    return tf.keras.Model(\r\n","        inputs = model_input,\r\n","        outputs = model_output,\r\n","        name = model_name)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"tO7sEoLHgSIs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612751068498,"user_tz":-540,"elapsed":930,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"e58ecc67-f7a6-41c2-b0dc-cb6223ea4f46"},"source":["tmp = VideoDiscriminator()\r\n","tmp.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"VideoDiscriminator\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_8 (InputLayer)         [(None, 16, 64, 64, 3)]   0         \n","_________________________________________________________________\n","zero_padding3d (ZeroPadding3 (None, 16, 66, 66, 3)     0         \n","_________________________________________________________________\n","conv3d_48 (Conv3D)           (None, 13, 32, 32, 64)    12352     \n","_________________________________________________________________\n","layer_normalization (LayerNo (None, 13, 32, 32, 64)    128       \n","_________________________________________________________________\n","activation_28 (Activation)   (None, 13, 32, 32, 64)    0         \n","_________________________________________________________________\n","zero_padding3d_1 (ZeroPaddin (None, 13, 34, 34, 64)    0         \n","_________________________________________________________________\n","conv3d_49 (Conv3D)           (None, 10, 16, 16, 128)   524416    \n","_________________________________________________________________\n","layer_normalization_1 (Layer (None, 10, 16, 16, 128)   256       \n","_________________________________________________________________\n","activation_29 (Activation)   (None, 10, 16, 16, 128)   0         \n","_________________________________________________________________\n","zero_padding3d_2 (ZeroPaddin (None, 10, 18, 18, 128)   0         \n","_________________________________________________________________\n","conv3d_50 (Conv3D)           (None, 7, 8, 8, 256)      2097408   \n","_________________________________________________________________\n","layer_normalization_2 (Layer (None, 7, 8, 8, 256)      512       \n","_________________________________________________________________\n","activation_30 (Activation)   (None, 7, 8, 8, 256)      0         \n","_________________________________________________________________\n","zero_padding3d_3 (ZeroPaddin (None, 7, 10, 10, 256)    0         \n","_________________________________________________________________\n","conv3d_51 (Conv3D)           (None, 4, 4, 4, 512)      8389120   \n","_________________________________________________________________\n","layer_normalization_3 (Layer (None, 4, 4, 4, 512)      1024      \n","_________________________________________________________________\n","activation_31 (Activation)   (None, 4, 4, 4, 512)      0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 1)                 32769     \n","_________________________________________________________________\n","activation_32 (Activation)   (None, 1)                 0         \n","=================================================================\n","Total params: 11,057,985\n","Trainable params: 11,057,985\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1nLP9w1giwd"},"source":["# tf.keras.utils.plot_model(tmp, show_shapes = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0DX5Q9HgmEt","executionInfo":{"status":"ok","timestamp":1612751072234,"user_tz":-540,"elapsed":749,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["del tmp"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JxBUjnIgQKQ","executionInfo":{"status":"ok","timestamp":1612751075197,"user_tz":-540,"elapsed":928,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def Conv2D_LN_LeakyReLU(\r\n","    x, \r\n","    filters, \r\n","    kernel_sz, \r\n","    strides = 1, \r\n","    padding = \"same\"\r\n","):\r\n","    x = tf.keras.layers.Conv2D(filters, kernel_sz, strides = strides, padding = padding)(x)\r\n","    x = tf.keras.layers.LayerNormalization()(x)\r\n","    x = tf.keras.layers.Activation(tf.nn.leaky_relu)(x)\r\n","    return x\r\n","\r\n","\r\n","def Shortcut(\r\n","    x, \r\n","    filters,\r\n","    kernel_sz = 1,\r\n","    pool_kernel_sz = 2,\r\n","    pool_strides = 2,\r\n","    pool_padding = \"same\"\r\n","):\r\n","    x = tf.keras.layers.AveragePooling2D(pool_kernel_sz, strides = pool_strides, padding = pool_padding)(x)\r\n","    x = tf.keras.layers.Conv2D(filters, kernel_sz)(x)\r\n","    return x\r\n","\r\n","\r\n","def ImageDiscriminator(\r\n","    model_name = \"ImageDiscriminator\",\r\n","):\r\n","    \"\"\"Resnet-based\"\"\"\r\n","    model_input = tf.keras.layers.Input(shape = HPARAMS.image_sz, dtype = tf.dtypes.float32)\r\n","\r\n","    ## L1.\r\n","    x = tf.keras.layers.Conv2D(3, 3, padding = \"same\")(model_input)\r\n","\r\n","    ## L2 to L8.\r\n","    for filters in [64, 128, 256, 512]:\r\n","        residual = Shortcut(x, filters = filters)\r\n","        x = Conv2D_LN_LeakyReLU(x, filters, 4, strides = 2)\r\n","        x = Conv2D_LN_LeakyReLU(x, filters, 3, strides = 1)\r\n","        x = tf.keras.layers.Add()([x, residual])\r\n","\r\n","    ## L9.\r\n","    x = tf.keras.layers.Flatten()(x)\r\n","    x = tf.keras.layers.Dense(1)(x)\r\n","    model_output = tf.keras.layers.Activation(tf.nn.sigmoid)(x)\r\n","\r\n","    return tf.keras.Model(\r\n","        inputs = model_input,\r\n","        outputs = model_output,\r\n","        name = model_name)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"6x8mkjXAbDP2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612751076554,"user_tz":-540,"elapsed":846,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"fde3f0f3-cfa8-43ee-ec89-353a850e5b46"},"source":["tmp = ImageDiscriminator()\r\n","tmp.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Model: \"ImageDiscriminator\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 64, 3)    84          input_9[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 32, 32, 64)   3136        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","layer_normalization_4 (LayerNor (None, 32, 32, 64)   128         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 32, 32, 64)   0           layer_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 32, 32, 64)   36928       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","layer_normalization_5 (LayerNor (None, 32, 32, 64)   128         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 32, 32, 3)    0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 32, 32, 64)   0           layer_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 32, 32, 64)   256         average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 32, 32, 64)   0           activation_34[0][0]              \n","                                                                 conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 128)  131200      add[0][0]                        \n","__________________________________________________________________________________________________\n","layer_normalization_6 (LayerNor (None, 16, 16, 128)  256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 16, 16, 128)  0           layer_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","layer_normalization_7 (LayerNor (None, 16, 16, 128)  256         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 16, 16, 64)   0           add[0][0]                        \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 16, 16, 128)  0           layer_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 128)  8320        average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 16, 16, 128)  0           activation_36[0][0]              \n","                                                                 conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 8, 8, 256)    524544      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","layer_normalization_8 (LayerNor (None, 8, 8, 256)    512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 8, 8, 256)    0           layer_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 8, 8, 256)    590080      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","layer_normalization_9 (LayerNor (None, 8, 8, 256)    512         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 8, 8, 128)    0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 8, 8, 256)    0           layer_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 8, 8, 256)    33024       average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 8, 8, 256)    0           activation_38[0][0]              \n","                                                                 conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 4, 4, 512)    2097664     add_2[0][0]                      \n","__________________________________________________________________________________________________\n","layer_normalization_10 (LayerNo (None, 4, 4, 512)    1024        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 4, 4, 512)    0           layer_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 4, 4, 512)    2359808     activation_39[0][0]              \n","__________________________________________________________________________________________________\n","layer_normalization_11 (LayerNo (None, 4, 4, 512)    1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 4, 4, 256)    0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 4, 4, 512)    0           layer_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 4, 4, 512)    131584      average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 4, 4, 512)    0           activation_40[0][0]              \n","                                                                 conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 8192)         0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","dense_25 (Dense)                (None, 1)            8193        flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 1)            0           dense_25[0][0]                   \n","==================================================================================================\n","Total params: 6,076,245\n","Trainable params: 6,076,245\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yjEwZS1th3pn"},"source":["# tf.keras.utils.plot_model(tmp, show_shapes = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHaUf5uObDLs","executionInfo":{"status":"ok","timestamp":1612751079146,"user_tz":-540,"elapsed":951,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["del tmp"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dRjIaEtiE9m"},"source":["## **Loss Function**"]},{"cell_type":"code","metadata":{"id":"0ZV4WOWkq5-1","executionInfo":{"status":"ok","timestamp":1612749022604,"user_tz":-540,"elapsed":741,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def DiscriminatorLoss(\r\n","    real_output,\r\n","    generated_output,\r\n","    epsilon = 1e-7\r\n","):\r\n","    \"\"\"Adopting the non-saturating log-loss for discriminators.\"\"\"\r\n","    real_loss = -1 * tf.math.log(real_output + epsilon)\r\n","    generated_loss = tf.math.log(tf.ones_like(generated_output) - generated_output + epsilon)\r\n","    total_disc_loss = tf.math.reduce_mean(real_loss + generated_loss)\r\n","\r\n","    return total_disc_loss\r\n","\r\n","\r\n","def GeneratorLoss(\r\n","    generated_video_output,\r\n","    generated_image_output,\r\n","    epsilon = 1e-7,\r\n","):\r\n","    \"\"\"Loss function for encoder, feature map generator, and video generator.\"\"\"\r\n","    generated_video_loss = -1 * tf.math.reduce_mean(tf.math.log(generated_video_output + epsilon))\r\n","    generated_image_loss = -1 * tf.math.reduce_mean(tf.math.log(generated_image_output + epsilon))\r\n","    total_gen_loss = generated_video_loss + generated_image_loss\r\n","\r\n","    return total_gen_loss"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlwY604c8_pq","executionInfo":{"status":"ok","timestamp":1612750675418,"user_tz":-540,"elapsed":764,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"377e8581-ac0a-4061-a71a-bafec743b35e"},"source":["## D_V\r\n","foo = tf.ones((32, 16, 64, 64, 3))  ## real_output\r\n","bar = tf.zeros((32, 16, 64, 64, 3)) ## generated_output\r\n","\r\n","DiscriminatorLoss(foo, bar)"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE186K-v8_nI","executionInfo":{"status":"ok","timestamp":1612747980788,"user_tz":-540,"elapsed":1149,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"f5310812-259c-46dc-ef2f-66acd3141949"},"source":["## D_I\r\n","foo = tf.ones((32, 14, 64, 64, 3))  ## real_output\r\n","bar = tf.zeros((32, 14, 64, 64, 3)) ## generated_output\r\n","\r\n","DiscriminatorLoss(foo, bar)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"BnhB4xvvisUR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612748014396,"user_tz":-540,"elapsed":740,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"ddd8e4ff-8636-498b-e14d-470e0fc20120"},"source":["## G := {E, G_Z, G_V}\r\n","foo = tf.ones((32, 16, 64, 64, 3))          ## generated_video_output\r\n","bar = tf.ones((32, 14, 64, 64, 3)) ## generated_image_output\r\n","\r\n","GeneratorLoss(foo, bar)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=-2.3841855e-07>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"cXfLx5opisOc"},"source":["## **Fit**"]},{"cell_type":"markdown","metadata":{"id":"yIZlakTFB9FG"},"source":["### **Generate Each Parts**"]},{"cell_type":"code","metadata":{"id":"pt_p4btjB8h-","executionInfo":{"status":"ok","timestamp":1612749886397,"user_tz":-540,"elapsed":3259,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["## Generator.\r\n","latent_representation_generator = LatentRepresentationGenerator(\r\n","    image_encoder = ImageEncoder(),\r\n","    video_generator = VideoGenerator())\r\n","\r\n","## Discriminator.\r\n","video_discriminator = VideoDiscriminator()\r\n","image_discriminator = ImageDiscriminator()"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLRdrQpJCB-R"},"source":["### **Optimizers and Checkpoints**"]},{"cell_type":"code","metadata":{"id":"m65S4bjv_ZTN","executionInfo":{"status":"ok","timestamp":1612749886400,"user_tz":-540,"elapsed":2874,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["generator_optimizer           = tf.keras.optimizers.Adam(lr = 5e-5, beta_1 = 0.5, beta_2 = 0.999, epsilon = 1e-8)\r\n","video_discriminator_optimizer = tf.keras.optimizers.Adam(lr = 5e-5, beta_1 = 0.5, beta_2 = 0.999, epsilon = 1e-8)\r\n","image_discriminator_optimizer = tf.keras.optimizers.Adam(lr = 5e-5, beta_1 = 0.5, beta_2 = 0.999, epsilon = 1e-8)"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEJ5s5Ou_ZQi","executionInfo":{"status":"ok","timestamp":1612749886402,"user_tz":-540,"elapsed":2661,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["checkpoint_dir = \"./training_checkpoints\"\r\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n","checkpoint = tf.train.Checkpoint(\r\n","    ## Optimizers.\r\n","    generator_optimizer = generator_optimizer,\r\n","    video_discriminator_optimizer = video_discriminator_optimizer,\r\n","    image_discriminator_optimizer = image_discriminator_optimizer,\r\n","\r\n","    ## Generators.\r\n","    latent_representation_generator = latent_representation_generator,\r\n","    \r\n","    ## Discriminators.\r\n","    video_discriminator = video_discriminator,\r\n","    image_discriminator = image_discriminator)"],"execution_count":86,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C0eu3H0z_ZNj"},"source":["### **Train**"]},{"cell_type":"code","metadata":{"id":"ogS44G2nYlNL","executionInfo":{"status":"ok","timestamp":1612749889209,"user_tz":-540,"elapsed":920,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["# !rm -rf logs"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"6LM8jMcD_ZK4","executionInfo":{"status":"ok","timestamp":1612749891543,"user_tz":-540,"elapsed":763,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["log_dir = \"logs/\"\r\n","\r\n","summary_writer = tf.summary.create_file_writer(\r\n","    log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmwUwQBBiE2q","executionInfo":{"status":"ok","timestamp":1612749902516,"user_tz":-540,"elapsed":3134,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["@tf.function\r\n","def train_step(videos, epoch):\r\n","    noise = tf.random.normal([videos.shape[0], HPARAMS.D]) ## not [HPARAMS.batch_sz, HPARAMS.D]\r\n","\r\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as video_disc_tape, tf.GradientTape() as image_disc_tape:\r\n","        ## Split key frames.\r\n","        x_s = videos[:, 0]\r\n","        x_e = videos[:, -1]\r\n","\r\n","        ## Genearte videos.\r\n","        generated_videos = latent_representation_generator([noise, x_s, x_e], training = True)\r\n","\r\n","        ## Discriminate videos/images.\r\n","        video_disc_output_for_real = video_discriminator(videos, training = True)\r\n","        video_disc_output_for_gen  = video_discriminator(generated_videos, training = True)\r\n","\r\n","        image_disc_output_for_real = tf.stack([\r\n","            image_discriminator(image, training = True) \\\r\n","            for image in tf.unstack(videos, axis = 1)[1:-1]], axis = 1)\r\n","        image_disc_output_for_gen  = tf.stack([\r\n","            image_discriminator(generated_image, training = True) \\\r\n","            for generated_image in tf.unstack(generated_videos, axis = 1)[1:-1]], axis = 1)\r\n","        \r\n","        ## Calculate losses.\r\n","        gen_loss = GeneratorLoss(video_disc_output_for_gen, image_disc_output_for_gen) \r\n","        disc_video_loss = DiscriminatorLoss(video_disc_output_for_real, video_disc_output_for_gen)\r\n","        disc_image_loss = DiscriminatorLoss(image_disc_output_for_real[1:-1], image_disc_output_for_gen[1:-1])\r\n","\r\n","    ## Calculate and apply gradients.\r\n","    gradients_of_generator = gen_tape.gradient(gen_loss, latent_representation_generator.trainable_variables)\r\n","    gradients_of_video_discriminator = video_disc_tape.gradient(disc_video_loss, video_discriminator.trainable_variables)\r\n","    gradients_of_image_discriminator = image_disc_tape.gradient(disc_image_loss, image_discriminator.trainable_variables)\r\n","        \r\n","    generator_optimizer.apply_gradients(\r\n","        zip(gradients_of_generator, latent_representation_generator.trainable_variables))\r\n","    video_discriminator_optimizer.apply_gradients(\r\n","        zip(gradients_of_video_discriminator, video_discriminator.trainable_variables))\r\n","    image_discriminator_optimizer.apply_gradients(\r\n","        zip(gradients_of_image_discriminator, image_discriminator.trainable_variables))\r\n","    \r\n","    ## Record loss graph.\r\n","    with summary_writer.as_default():\r\n","        tf.summary.scalar(\"gen_loss\", gen_loss, step = epoch)\r\n","        tf.summary.scalar(\"disc_video_loss\", disc_video_loss, step = epoch)\r\n","        tf.summary.scalar(\"disc_image_loss\", disc_image_loss, step = epoch)"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuAq6EkmKqzp","executionInfo":{"status":"ok","timestamp":1612749927930,"user_tz":-540,"elapsed":714,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def train(\r\n","    dataset, \r\n","    epochs = HPARAMS.epochs,\r\n","):\r\n","    for epoch in range(epochs):\r\n","        start = time.time()\r\n","\r\n","        for image_batch in dataset:\r\n","            train_step(image_batch, epoch)\r\n","\r\n","        ## Save model every epochs.\r\n","        checkpoint.save(file_prefix = checkpoint_prefix)\r\n","\r\n","        ## Display training times of each epochs.\r\n","        print (f\"Time for epoch {epoch + 1} is {time.time() - start:.2f} sec\")"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IesDatxFLgrJ","executionInfo":{"status":"ok","timestamp":1612750356453,"user_tz":-540,"elapsed":426614,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"6f93e353-f9ad-44da-f5ef-70c83e17c4a8"},"source":["%%time\r\n","## Dummy training dataset with 100 videos.\r\n","dummy_tr_tensor = tf.random.uniform(shape = [100] + HPARAMS.video_sz, maxval = 1.)\r\n","dummy_tr_dataset = tf.data.Dataset.from_tensor_slices(dummy_tr_tensor) \\\r\n","                            .batch(HPARAMS.batch_sz) \\\r\n","                            .cache() \\\r\n","                            .prefetch(-1)\r\n","\r\n","train(dummy_tr_dataset)"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Time for epoch 1 is 103.76 sec\n","Time for epoch 2 is 80.82 sec\n","WARNING:tensorflow:5 out of the last 9 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Time for epoch 3 is 80.79 sec\n","WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Time for epoch 4 is 80.33 sec\n","WARNING:tensorflow:7 out of the last 13 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 12 calls to <function train_step at 0x7fe74d03ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Time for epoch 5 is 80.09 sec\n","CPU times: user 6min 54s, sys: 13.1 s, total: 7min 7s\n","Wall time: 7min 5s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tbd1NPrwV-Wi"},"source":["%load_ext tensorboard\r\n","%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QH3KzHGbc-Fe"},"source":[""],"execution_count":null,"outputs":[]}]}
# **Paper Implementation with AI**

The goal of this repository is to implement the model architecture, loss function, and others proposed in elegant AI papers with my own code, especially tensorflow 2.x.

Regardless of the detailed field, we aim to acquire the knowledge in as many different fields as possible. (speaker verification, image classification, GAN, optimizer, etc.)

## **Papers**

[[001]](https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html) Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). **Densely connected convolutional networks**. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 4700-4708).

[[002]](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) Ronneberger, O., Fischer, P., & Brox, T. (2015, October). **U-net: Convolutional networks for biomedical image segmentation**. In *International Conference on Medical image computing and computer-assisted intervention* (pp. 234-241). Springer, Cham.

[[003]](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html) He, K., Zhang, X., Ren, S., & Sun, J. (2016). **Deep residual learning for image recognition**. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 770-778).

[[004]](https://arxiv.org/abs/1905.10240) Li, Y., Roblek, D., & Tagliasacchi, M. (2019). **From here to there: Video inbetweening using direct 3d convolutions**. *arXiv preprint arXiv:1905.10240*.

[[005]](https://openaccess.thecvf.com/content_cvpr_2017/html/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.html) Xie, S., Girshick, R., Doll√°r, P., Tu, Z., & He, K. (2017). **Aggregated residual transformations for deep neural networks**. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 1492-1500).

[[006]](http://proceedings.mlr.press/v54/mcmahan17a.html) McMahan, B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2017, April). **Communication-efficient learning of deep networks from decentralized data**. In *Artificial Intelligence and Statistics* (pp. 1273-1282). PMLR.

[[007]](https://arxiv.org/abs/1904.08104) Jung, J. W., Heo, H. S., Kim, J. H., Shim, H. J., & Yu, H. J. (2019). **Rawnet: Advanced end-to-end deep neural network using raw waveforms for text-independent speaker verification**. *arXiv preprint arXiv:1904.08104*.

[[008]](https://openaccess.thecvf.com/content_CVPR_2019/html/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.html) Deng, J., Guo, J., Xue, N., & Zafeiriou, S. (2019). **Arcface: Additive angular margin loss for deep face recognition**. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 4690-4699).

[[009]](https://arxiv.org/abs/1704.04861) Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., ... & Adam, H. (2017). **Mobilenets: Efficient convolutional neural networks for mobile vision applications**. *arXiv preprint arXiv:1704.04861*.

[[010]](https://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html) Zhang, X., Zhou, X., Lin, M., & Sun, J. (2018). **Shufflenet: An extremely efficient convolutional neural network for mobile devices**. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 6848-6856).

[[011]](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf) Koch, G., Zemel, R., & Salakhutdinov, R. (2015, July). **Siamese neural networks for one-shot image recognition**. In *ICML deep learning workshop* (Vol. 2).

[[012]](https://arxiv.org/abs/1710.09829) Sabour, S., Frosst, N., & Hinton, G. E. (2017). **Dynamic routing between capsules**. *arXiv preprint arXiv:1710.09829*.

[[013]](https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html) Hu, J., Shen, L., & Sun, G. (2018). **Squeeze-and-excitation networks**. In *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 7132-7141).

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[022] Mixed Precision Training.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyP0PAL8xhuEpclb2OT4PQx6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dguDJqATBTpc"},"source":["# **Mixed Precision Training**\n","\n","Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D., ... & Wu, H. (2017). Mixed precision training. arXiv preprint arXiv:1710.03740.\n","\n","Every experimental results are committed to Tensorboard Dev, and you can access them as blow:\n","\n","*https://tensorboard.dev/experiment/lYlje1KYQ1KULHjd2Qj9jw/*"]},{"cell_type":"markdown","metadata":{"id":"IQNcSOa4Bb_C"},"source":["## **Default Setting**"]},{"cell_type":"code","metadata":{"id":"HGV8OnwCBRD9","executionInfo":{"status":"ok","timestamp":1618297620460,"user_tz":-540,"elapsed":3656,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["!pip3 install -q tensorflow-datasets"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwwDLVEjBfRX","executionInfo":{"status":"ok","timestamp":1618297622406,"user_tz":-540,"elapsed":5591,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"7f74d0a9-5cb2-49e4-aee0-7934a71b60e4"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","import math\n","import os\n","\n","print(f\"tf.__version__: {tf.__version__}\")\n","print(f\"tfds.__version__: {tfds.__version__}\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tf.__version__: 2.4.1\n","tfds.__version__: 4.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpGA3UZpBfOg","executionInfo":{"status":"ok","timestamp":1618297622407,"user_tz":-540,"elapsed":5292,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"db176578-c70f-4398-9660-e2780928ba4b"},"source":["## Using NVIDIA Tesla V100.\n","!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Tue Apr 13 07:07:00 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d2f0bj9bBfLP","executionInfo":{"status":"ok","timestamp":1618297622408,"user_tz":-540,"elapsed":4676,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["class HParams(object):\n","    def __init__(self):\n","        self.steps_per_epoch = None\n","        self.steps_per_execution = 16\n","\n","        self.global_batch_sz = 128\n","        self.buffer_sz = 20_000\n","        self.auto = tf.data.experimental.AUTOTUNE\n","\n","        self.image_sz = [224, 224]\n","\n","        self.learning_rate = 1e-3\n","        self.epochs = 20\n","        self.steps_per_epoch = None\n","        self.validation_steps = None\n","\n","HPARAMS = HParams()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GO5Mo0q-BfIr"},"source":["## **Prepare Dataset**"]},{"cell_type":"code","metadata":{"id":"luM1y-8hCOyF","executionInfo":{"status":"ok","timestamp":1618297622408,"user_tz":-540,"elapsed":3647,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["@tf.function\n","def resize_and_rescale(image, label):\n","    image = tf.image.resize(image, HPARAMS.image_sz) ## resizing\n","    image = tf.cast(image, tf.float32) / 255. ## rescaling\n","    label = tf.cast(label, tf.float32)\n","    return image, label\n","\n","\n","def get_shapes(element_spec):\n","    return [get_shapes(e) if isinstance(e, tuple) else e.shape for e in element_spec]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3P_uOgvBfDC","executionInfo":{"status":"ok","timestamp":1618297622410,"user_tz":-540,"elapsed":3375,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def get_dataset(is_mixed_precision_training = True):\n","    ## Load dataset from tfds.\n","    tr_ds = tfds.load(\n","        \"cifar100\", \n","        split = \"train\", \n","        as_supervised = True,\n","    )\n","    ## Mixing with the seeds fixed ensures the same train \n","    ## and validation dataset even after the runtime is restarted.\n","    tr_ds = tr_ds.shuffle(100_000, seed = 42)\n","\n","    ts_ds = tfds.load(\n","        \"cifar100\", \n","        split = \"test\", \n","        as_supervised = True,\n","    )\n","\n","    ## Building.\n","    vl_ds = tr_ds.take(10_000\n","                ).cache(\n","                ).repeat(\n","                # ).shuffle(HPARAMS.buffer_sz, reshuffle_each_iteration = True,\n","                ).batch(HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)\n","                ).map(resize_and_rescale, num_parallel_calls = HPARAMS.auto\n","                ).prefetch(HPARAMS.auto)\n","\n","    tr_ds = tr_ds.skip(10_000\n","                ).cache(\n","                ).repeat(\n","                ).shuffle(HPARAMS.buffer_sz, reshuffle_each_iteration = True,\n","                ).batch(HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)\n","                ).map(resize_and_rescale, num_parallel_calls = HPARAMS.auto\n","                ).prefetch(HPARAMS.auto)\n","\n","    ts_ds = ts_ds.cache(\n","                # ).shuffle(HPARAMS.buffer_sz, reshuffle_each_iteration = True,\n","                ).batch(HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)\n","                ).map(resize_and_rescale, num_parallel_calls = HPARAMS.auto\n","                ).prefetch(HPARAMS.auto)\n","    \n","    steps_per_epoch = 40_000 // (HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)) + 1\n","    validation_steps = 10_000 // (HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)) + 1\n","    \n","    HPARAMS.steps_per_epoch = steps_per_epoch\n","    HPARAMS.validation_steps = validation_steps\n","\n","    print(f\"Global batch size: {HPARAMS.global_batch_sz * (2 if is_mixed_precision_training else 1)}\")\n","    print(f\"Steps per epoch: {steps_per_epoch} (total {steps_per_epoch * HPARAMS.epochs} batches)\")\n","    print(f\"Validation steps: {validation_steps} (total {validation_steps * HPARAMS.epochs} batches)\")\n","\n","    print(f\"\\ntr_ds.element_spec: {get_shapes(tr_ds.element_spec)}\")\n","    print(f\"ts_ds.element_spec: {get_shapes(ts_ds.element_spec)}\\n\")\n","\n","    return tr_ds, vl_ds, ts_ds"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPlMNi8BBe9j"},"source":["## **Modeling**"]},{"cell_type":"code","metadata":{"id":"pzU0LuFjBe67","executionInfo":{"status":"ok","timestamp":1618297622411,"user_tz":-540,"elapsed":2844,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def SE_Block(\n","    x,\n","    reduction_rate = 24,\n","    apply_type = \"transformed\",\n","):\n","    assert not (x.shape[-1] % reduction_rate), f\"x.shape {x.shape} must be divided by reduction_rate {reduction_rate}\"\n","    assert apply_type.lower() in [\"textbook\", \"transformed\"]\n","    \n","    residual = x\n","\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    x = tf.keras.layers.Reshape((1, 1, -1))(x)\n","\n","    if apply_type.lower() == \"textbook\":\n","        ## This is the method actually applied in the original paper.\n","        x = tf.keras.layers.Dense(x.shape[-1] // reduction_rate)(x)\n","        x = tf.keras.layers.Activation(tf.nn.relu6)(x)\n","\n","        x = tf.keras.layers.Dense(residual.shape[-1])(x)\n","        x = tf.keras.layers.Activation(tf.nn.sigmoid)(x)\n","\n","    else:\n","        ## This is the method that expands the existing block.\n","        ## It's not sure if the activation function has been \n","        ## applied, but I think it might have been applied.\n","        x = tf.keras.layers.Conv2D(x.shape[-1] // reduction_rate, 1, padding = \"same\")(x)\n","        x = tf.keras.layers.Activation(tf.nn.relu6)(x)\n","\n","        x = tf.keras.layers.Conv2D(residual.shape[-1], 1, padding = \"same\")(x)\n","        x = tf.keras.layers.Activation(tf.nn.sigmoid)(x)\n","        \n","    x = tf.keras.layers.Multiply()([x, residual]) ## channel-wise multiplication\n","    \n","    return x"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HI_h8FeIBe4A","executionInfo":{"status":"ok","timestamp":1618297622411,"user_tz":-540,"elapsed":2623,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def round_filters(filters, width_coefficient, depth_divisor = 8):\n","    \"\"\"Round number of filters based on width multiplier.\"\"\"\n","\n","    filters *= width_coefficient\n","    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n","    new_filters = max(depth_divisor, new_filters)\n","    ## Make sure that round down does not go down by more than 10%.\n","    if new_filters < 0.9 * filters:\n","        new_filters += depth_divisor\n","        \n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, depth_coefficient):\n","    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n","\n","    return int(math.ceil(depth_coefficient * repeats))\n","\n","\n","def ConvBNReLU(\n","    x, \n","    layer_type, \n","    output_channels = None,\n","    kernel_size = 3,\n","    strides = 1, \n","    activation_fn = tf.nn.relu6, \n","    expansion_factor = 6, \n","    reduction_rate = 24,\n","):\n","    assert layer_type.lower() in [\"expansion\", \"depthwise\", \"pointwise\", \"naive\"]\n","\n","    if layer_type.lower() == \"expansion\":\n","        ## Conv 1x1\n","        x = tf.keras.layers.Conv2D(x.shape[-1] * expansion_factor, 1, padding = \"same\")(x)\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        x = tf.keras.layers.Activation(activation_fn)(x)\n","\n","    elif layer_type.lower() == \"depthwise\":\n","        ## Dwise 3x3\n","        x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides = strides, padding = \"same\")(x)\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        x = tf.keras.layers.Activation(activation_fn)(x)\n","\n","        ## SE_Block is only bound behind a depthwise convolution.\n","        scaled_reduction_rate = 4 if x.shape[-1] % reduction_rate else reduction_rate\n","        \n","        x = SE_Block(x, scaled_reduction_rate)\n","    \n","    elif layer_type.lower() == \"pointwise\":\n","        ## Conv 1x1\n","        assert output_channels != None\n","        x = tf.keras.layers.Conv2D(output_channels, 1, padding = \"same\")(x) ## no activation, i.e. use linear.\n","        x = tf.keras.layers.BatchNormalization()(x)\n","\n","    else: ## naive\n","        assert output_channels != None\n","        x = tf.keras.layers.Conv2D(output_channels, kernel_size, strides = strides, padding = \"same\")(x)\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        x = tf.keras.layers.Activation(activation_fn)(x)\n","\n","    return x\n","\n","\n","def InvertResidualBlock(\n","    x, \n","    output_channels,\n","    kernel_size = 3, \n","    strides = 1,\n","    expansion_factor = 6,\n","):\n","    assert strides in [1, 2], f\"Argument 'strides' must be 1 or 2, not {strides}.\"\n","    residual = x\n","\n","    x = ConvBNReLU(x, \"expansion\", kernel_size = kernel_size, expansion_factor = expansion_factor)\n","    x = ConvBNReLU(x, \"depthwise\", kernel_size = kernel_size, expansion_factor = expansion_factor, strides = strides,)\n","    x = ConvBNReLU(x, \"pointwise\", kernel_size = kernel_size, expansion_factor = expansion_factor, output_channels = output_channels)\n","\n","    if strides == 1 and x.shape[-1] == residual.shape[-1]:\n","        x = tf.keras.layers.Add()([x, residual])\n","\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ef1UN-W9Bekr","executionInfo":{"status":"ok","timestamp":1618297622411,"user_tz":-540,"elapsed":2415,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def EfficientNet(\n","    compound_coefficient = 0, \n","    prefix = None,\n",") -> tf.keras.Model:\n","\n","    assert compound_coefficient in range(8), \\\n","        f\"Compound scaling coefficient phi must be in range [0, 7], not {compound_coefficient}\"\n","\n","    def EfficientNet_Baseline(\n","        depth_coefficient, \n","        width_coefficient, \n","        image_size, \n","        model_name, \n","        reduction_rate = 24,\n","        embedding_dims = 100, \n","        apply_classifier = True,\n","    ) -> tf.keras.Model:\n","        ## Readjust resolution from gamma.\n","        x = model_input = tf.keras.layers.Input(shape = (image_size, image_size, 3))\n","\n","        ## Entry flow (stem).\n","        x = ConvBNReLU(x, \"naive\", kernel_size = 3, strides = 2, output_channels = 32)\n","        x = InvertResidualBlock(x, 16, expansion_factor = 1)\n","\n","        ## Middle flow.\n","        ## It means (filters, kernel size, repeats, stride).\n","        args = [\n","            (24,  3, 2, 2),\n","            (40,  5, 2, 2),\n","            (80,  3, 3, 2),\n","            (112, 5, 3, 1),\n","            (192, 5, 4, 2),\n","            (320, 3, 1, 1)]\n","        \n","        for (filters, kernel_size, repeats, strides) in args:\n","            ## Newly scaled parameters are delivered while retaining the existing arguments.\n","            scaled_filters = round_filters(filters, width_coefficient)\n","            scaled_repeats = round_repeats(repeats, depth_coefficient)\n","\n","            ## The first layer of each sequence has a stride s and all others use stride 1.\n","            x = InvertResidualBlock(x, scaled_filters, kernel_size = kernel_size, strides = strides)\n","            for _ in range(1, scaled_repeats):\n","                x = InvertResidualBlock(x, scaled_filters, kernel_size = kernel_size, strides = 1)\n","\n","        ## Exit flow.\n","        x = ConvBNReLU(x, \"naive\", kernel_size = 1, output_channels = 1_280)\n","        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","        model_output = x = tf.keras.layers.Dense(embedding_dims)(x) ## fixed\n","        if apply_classifier:\n","            model_output = tf.keras.layers.Softmax(dtype = tf.float32)(model_output)\n","            \n","        return tf.keras.Model(\n","            inputs = model_input,\n","            outputs = model_output,\n","            name = model_name)\n","\n","    ## The textbook coefficient is as follows, \n","    ## but it is actually adjusted slightly and applied.\n","    \"\"\"\n","        depth_coefficient = 1.2\n","        width_coefficient = 1.1\n","        resol_coefficient = 1.15\n","\n","        scaled_depth_coefficient = depth_coefficient ** compound_coefficient\n","        scaled_width_coefficient = width_coefficient ** (compound_coefficient * 0.5)\n","        scaled_resol_coefficient = resol_coefficient ** (compound_coefficient * 0.5)\n","    \"\"\"\n","\n","    coefficient_args = {\n","        0: (1.0, 1.0, 224),\n","        1: (1.0, 1.1, 240),\n","        2: (1.1, 1.2, 260),\n","        3: (1.2, 1.4, 300),\n","        4: (1.4, 1.8, 380),\n","        5: (1.6, 2.2, 456),\n","        6: (1.8, 2.6, 528),\n","        7: (2.0, 3.1, 600)}\n","        \n","    return EfficientNet_Baseline(\n","        *coefficient_args[compound_coefficient],\n","        model_name = f\"EfficientNet-B{compound_coefficient}-{prefix}\"\n","    )"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZvdCsmOEMDT"},"source":["## **Callbacks**"]},{"cell_type":"code","metadata":{"id":"VIiNvnJtENBp","executionInfo":{"status":"ok","timestamp":1618297622411,"user_tz":-540,"elapsed":690,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}}},"source":["def get_callbacks(model_name):    \n","    ## TensorBoard callback.\n","    log_dir = f\"logs/fit/{model_name}\"\n","    os.makedirs(os.path.dirname(log_dir), exist_ok = True)\n","\n","    tb_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)\n","    \n","    return [tb_callback]"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UetUICwzBt49"},"source":["## **Baseline with FP32**\n","\n","The batch size sets the maximum size possible with the current VRAM capacity. When the batch size is 256, a ResourceExhauseError (Out-of-Memory; OOM) occurs, so 128, which is half the size, is used as the default batch size."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_SY_NohFEeZX","executionInfo":{"status":"ok","timestamp":1618297509396,"user_tz":-540,"elapsed":3233349,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"04940cab-fe2b-41ce-8268-7b41769bad48"},"source":["tr_ds, vl_ds, ts_ds = get_dataset(is_mixed_precision_training = False)\n","\n","model = EfficientNet(prefix = \"baseline\")\n","model.compile(\n","    optimizer = \"adam\",\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics = [\"acc\"],\n","    steps_per_execution = HPARAMS.steps_per_execution,\n",")\n","\n","model.fit(\n","    tr_ds,\n","    validation_data = vl_ds,\n","    steps_per_epoch = HPARAMS.steps_per_epoch,\n","    validation_steps = HPARAMS.validation_steps,\n","    epochs = HPARAMS.epochs,\n","    verbose = 2,\n","    callbacks = get_callbacks(model.name),\n",")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Global batch size: 128\n","Steps per epoch: 313 (total 6260 batches)\n","Validation steps: 79 (total 1580 batches)\n","\n","tr_ds.element_spec: [TensorShape([None, 224, 224, 3]), TensorShape([None])]\n","ts_ds.element_spec: [TensorShape([None, 224, 224, 3]), TensorShape([None])]\n","\n","Epoch 1/20\n","313/313 - 186s - loss: 3.6864 - acc: 0.1325 - val_loss: 5.5154 - val_acc: 0.0097\n","Epoch 2/20\n","313/313 - 158s - loss: 2.8268 - acc: 0.2764 - val_loss: 5.0246 - val_acc: 0.1029\n","Epoch 3/20\n","313/313 - 158s - loss: 2.2828 - acc: 0.3902 - val_loss: 3.7533 - val_acc: 0.2573\n","Epoch 4/20\n","313/313 - 160s - loss: 1.9197 - acc: 0.4672 - val_loss: 3.6222 - val_acc: 0.2817\n","Epoch 5/20\n","313/313 - 159s - loss: 1.6460 - acc: 0.5317 - val_loss: 2.5104 - val_acc: 0.4002\n","Epoch 6/20\n","313/313 - 159s - loss: 1.4266 - acc: 0.5900 - val_loss: 2.0562 - val_acc: 0.4785\n","Epoch 7/20\n","313/313 - 160s - loss: 1.2413 - acc: 0.6359 - val_loss: 1.6746 - val_acc: 0.5484\n","Epoch 8/20\n","313/313 - 160s - loss: 1.0774 - acc: 0.6781 - val_loss: 2.3834 - val_acc: 0.4481\n","Epoch 9/20\n","313/313 - 161s - loss: 0.9393 - acc: 0.7152 - val_loss: 1.4850 - val_acc: 0.6064\n","Epoch 10/20\n","313/313 - 160s - loss: 0.7970 - acc: 0.7544 - val_loss: 0.9960 - val_acc: 0.7147\n","Epoch 11/20\n","313/313 - 160s - loss: 0.6711 - acc: 0.7909 - val_loss: 1.1561 - val_acc: 0.6856\n","Epoch 12/20\n","313/313 - 161s - loss: 0.5720 - acc: 0.8191 - val_loss: 1.1413 - val_acc: 0.6907\n","Epoch 13/20\n","313/313 - 162s - loss: 0.4934 - acc: 0.8420 - val_loss: 0.9911 - val_acc: 0.7393\n","Epoch 14/20\n","313/313 - 161s - loss: 0.4082 - acc: 0.8672 - val_loss: 1.1064 - val_acc: 0.7162\n","Epoch 15/20\n","313/313 - 160s - loss: 0.3616 - acc: 0.8811 - val_loss: 1.0587 - val_acc: 0.7438\n","Epoch 16/20\n","313/313 - 160s - loss: 0.3122 - acc: 0.8965 - val_loss: 0.7439 - val_acc: 0.8159\n","Epoch 17/20\n","313/313 - 160s - loss: 0.2629 - acc: 0.9122 - val_loss: 0.9614 - val_acc: 0.7626\n","Epoch 18/20\n","313/313 - 158s - loss: 0.2454 - acc: 0.9193 - val_loss: 0.9276 - val_acc: 0.7887\n","Epoch 19/20\n","313/313 - 158s - loss: 0.2330 - acc: 0.9231 - val_loss: 0.8949 - val_acc: 0.7870\n","Epoch 20/20\n","313/313 - 160s - loss: 0.2053 - acc: 0.9320 - val_loss: 0.9250 - val_acc: 0.7868\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8df75341d0>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7KKJhwJqpkz","executionInfo":{"status":"ok","timestamp":1618297565554,"user_tz":-540,"elapsed":7355,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"ab47945c-b745-47f3-c520-1526ecf786ff"},"source":["model.evaluate(ts_ds, verbose = 2)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["79/79 - 6s - loss: 2.8551 - acc: 0.5242\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.8550562858581543, 0.5242000222206116]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Ai_aLln5Bt-n"},"source":["## **Mixed Precision with FP16**\n","\n","There is no difference from the baseline except that the batch size is doubling and the steps per epoch become smaller accordingly. However, to apply the mixed precision policy, you must restart the runtime. (ctrl + m, dot)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXXt0STEs-89","executionInfo":{"status":"ok","timestamp":1618297626560,"user_tz":-540,"elapsed":819,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"12795a0d-4721-4af5-ef9f-c0f491894a78"},"source":["tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n","Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-16GB, compute capability 7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUOPICpvBuBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618299034141,"user_tz":-540,"elapsed":1403402,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"ecfea457-40f7-4ade-d698-09e8cde5351f"},"source":["tr_ds, vl_ds, ts_ds = get_dataset(is_mixed_precision_training = True)\n","\n","model = EfficientNet(prefix = \"mixed-precision\")\n","model.compile(\n","    optimizer = \"adam\",\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics = [\"acc\"],\n","    steps_per_execution = HPARAMS.steps_per_execution,\n",")\n","\n","model.fit(\n","    tr_ds,\n","    validation_data = vl_ds,\n","    steps_per_epoch = HPARAMS.steps_per_epoch,\n","    validation_steps = HPARAMS.validation_steps,\n","    epochs = HPARAMS.epochs,\n","    verbose = 2,\n","    callbacks = get_callbacks(model.name),\n",")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Global batch size: 256\n","Steps per epoch: 157 (total 3140 batches)\n","Validation steps: 40 (total 800 batches)\n","\n","tr_ds.element_spec: [TensorShape([None, 224, 224, 3]), TensorShape([None])]\n","ts_ds.element_spec: [TensorShape([None, 224, 224, 3]), TensorShape([None])]\n","\n","Epoch 1/20\n","157/157 - 109s - loss: 3.7674 - acc: 0.1204 - val_loss: 5.0847 - val_acc: 0.0087\n","Epoch 2/20\n","157/157 - 67s - loss: 2.9313 - acc: 0.2561 - val_loss: 5.5176 - val_acc: 0.0087\n","Epoch 3/20\n","157/157 - 67s - loss: 2.4018 - acc: 0.3663 - val_loss: 7.6578 - val_acc: 0.0104\n","Epoch 4/20\n","157/157 - 67s - loss: 2.0121 - acc: 0.4535 - val_loss: 3.1316 - val_acc: 0.2826\n","Epoch 5/20\n","157/157 - 67s - loss: 1.7234 - acc: 0.5163 - val_loss: 2.7835 - val_acc: 0.3612\n","Epoch 6/20\n","157/157 - 67s - loss: 1.4798 - acc: 0.5759 - val_loss: 2.8795 - val_acc: 0.3631\n","Epoch 7/20\n","157/157 - 67s - loss: 1.2959 - acc: 0.6212 - val_loss: 1.8614 - val_acc: 0.4996\n","Epoch 8/20\n","157/157 - 67s - loss: 1.1056 - acc: 0.6725 - val_loss: 1.8476 - val_acc: 0.5216\n","Epoch 9/20\n","157/157 - 67s - loss: 0.9427 - acc: 0.7192 - val_loss: 1.7386 - val_acc: 0.5398\n","Epoch 10/20\n","157/157 - 67s - loss: 0.7840 - acc: 0.7596 - val_loss: 2.1141 - val_acc: 0.5058\n","Epoch 11/20\n","157/157 - 67s - loss: 0.6652 - acc: 0.7948 - val_loss: 1.3864 - val_acc: 0.6405\n","Epoch 12/20\n","157/157 - 67s - loss: 0.5528 - acc: 0.8256 - val_loss: 1.5023 - val_acc: 0.6185\n","Epoch 13/20\n","157/157 - 67s - loss: 0.4592 - acc: 0.8535 - val_loss: 1.0396 - val_acc: 0.7143\n","Epoch 14/20\n","157/157 - 67s - loss: 0.3657 - acc: 0.8822 - val_loss: 1.1667 - val_acc: 0.6986\n","Epoch 15/20\n","157/157 - 67s - loss: 0.3203 - acc: 0.8967 - val_loss: 1.2132 - val_acc: 0.7046\n","Epoch 16/20\n","157/157 - 67s - loss: 0.2745 - acc: 0.9109 - val_loss: 1.1887 - val_acc: 0.7189\n","Epoch 17/20\n","157/157 - 67s - loss: 0.2405 - acc: 0.9230 - val_loss: 0.8360 - val_acc: 0.7962\n","Epoch 18/20\n","157/157 - 67s - loss: 0.2117 - acc: 0.9304 - val_loss: 0.8450 - val_acc: 0.7959\n","Epoch 19/20\n","157/157 - 67s - loss: 0.1669 - acc: 0.9462 - val_loss: 1.0891 - val_acc: 0.7506\n","Epoch 20/20\n","157/157 - 67s - loss: 0.1914 - acc: 0.9375 - val_loss: 0.9568 - val_acc: 0.7787\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4ac802b550>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Xqu0LYJiBuEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618299850702,"user_tz":-540,"elapsed":7265,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"a71eda85-388d-454c-b411-a9cfc2aaed37"},"source":["model.evaluate(ts_ds, verbose = 2)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["40/40 - 6s - loss: 2.8439 - acc: 0.5059\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.8438925743103027, 0.5059000253677368]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"vQqxH5GmBuG4"},"source":["## **Commit to Tensorboard Dev.**"]},{"cell_type":"code","metadata":{"id":"wLPx2IcfBuJe"},"source":["!tensorboard dev upload --logdir ./logs \\\n","    --name \"Experiment of 'Mixed Precision Training'\" \\\n","    --description \"Implemented training results from the paper 'https://arxiv.org/abs/1710.03740'\" \\\n","    --one_shot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSiZOwcsBuMY","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1618299989746,"user_tz":-540,"elapsed":721,"user":{"displayName":"Myung-Gyo Oh","photoUrl":"","userId":"01040732127983096879"}},"outputId":"271f4ed2-8db2-45cd-9dad-32f096344d84"},"source":["from IPython import display\n","\n","display.IFrame(\n","    src = \"https://tensorboard.dev/experiment/lYlje1KYQ1KULHjd2Qj9jw/\",\n","    width = \"100%\",\n","    height = \"1000px\"\n",")"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"1000px\"\n","            src=\"https://tensorboard.dev/experiment/lYlje1KYQ1KULHjd2Qj9jw/\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7f4a7493bc90>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"qb7VScYEBuSk"},"source":[""],"execution_count":null,"outputs":[]}]}